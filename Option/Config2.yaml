llm:
  api_type: "open_llm"  # 使用OpenLLM本地部署
  base_url: "http://localhost:6578/v1"  # 你的本地服务地址
  model: "meta-llama/Meta-Llama-3.1-8B-Instruct"  # LLM模型名称
  api_key: "not-needed"  # 本地部署不需要真实API key
  max_token: 2048 
  context_length: 32768

embedding:
  api_type: "hf"  
  api_key: "not-needed"  
  model: "all-MiniLM-L6-v2"  
  cache_dir: ""
  dimensions: 1024
  max_token_size: 8102
  embed_batch_size: 128
  embedding_func_max_async: 16
 
data_root:  "/mnt/temp"

working_dir: /home/mengke/code/GraphRAG/run # Result directory for the experiment
exp_name:  test # Experiment name
# 